{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (4.1.0.25)\nRequirement already satisfied: numpy>=1.11.3 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from opencv-python) (1.16.2)\n\u001b[33mWARNING: You are using pip version 19.1, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: keras in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (2.2.4)\nRequirement already satisfied, skipping upgrade: pyyaml in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (3.13)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (1.16.2)\nRequirement already satisfied, skipping upgrade: scipy>=0.14 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (1.1.0)\nRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (1.0.7)\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (1.0.9)\nRequirement already satisfied, skipping upgrade: six>=1.9.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (1.11.0)\nRequirement already satisfied, skipping upgrade: h5py in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras) (2.8.0)\n\u001b[33mWARNING: You are using pip version 19.1, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    images = tf.placeholder(tf.float32, (None, *input_shape), name='images')\n",
    "    labels = tf.placeholder(tf.int32, (None, ), name='labels')\n",
    "    \n",
    "    with tf.variable_scope('preprocess'):\n",
    "        image_mean = tf.constant([123.68, 116.779, 103.939])\n",
    "        x = images - image_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.initializers.he_uniform()\n",
    "xavier_init = tf.initializers.glorot_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inception_module(prev_layer,\n",
    "                    one_conv_filters,\n",
    "                    reduced_three_filters,\n",
    "                    three_conv_filters,\n",
    "                    reduced_five_filters,\n",
    "                    five_conv_filters,\n",
    "                    after_poll_filters,\n",
    "                    module_name='inception'):\n",
    "\n",
    "    with tf.variable_scope(module_name):\n",
    "        out1 = tf.layers.Conv2D(one_conv_filters, (1,1), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='1x1_conv')(prev_layer)\n",
    "        \n",
    "        out2 = tf.layers.Conv2D(reduced_three_filters, (1,1), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='3x3_reduced')(prev_layer)\n",
    "        out2 = tf.layers.Conv2D(three_conv_filters, (3,3), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='3x3_conv')(out2)\n",
    "        \n",
    "        out3 = tf.layers.Conv2D(reduced_five_filters, (1,1), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='5x5_reduced')(prev_layer)\n",
    "        out3 = tf.layers.Conv2D(five_conv_filters, (5,5), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='5x5_conv')(out3)\n",
    "        \n",
    "        out4 = tf.layers.MaxPooling2D((3,3), (1,1), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='3x3_pool')(prev_layer)\n",
    "        out4 = tf.layers.Conv2D(five_conv_filters, (5,5), padding='SAME',kernel_initializer=he_init,activation=tf.nn.relu,name='after_pool')(out4)\n",
    "        \n",
    "        out = tf.concat([out1,out2,out3,out4], axis=-1, name='filter_concatenation')\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    he_init = tf.initializers.he_uniform()\n",
    "    \n",
    "    conv1 = tf.layers.Conv2D(64, (7,7), (2,2), padding='SAME',\n",
    "                            kernel_initializer=he_init,\n",
    "                            name='7x7_conv')(x)\n",
    "    pool1 = tf.layers.MaxPooling2D((3,3),(2,2),name='MaxPool_1')(conv1)\n",
    "    conv2 = tf.layers.Conv2D(192, (3,3), padding='SAME',\n",
    "                             kernel_initializer=he_init,\n",
    "                             name='3x3_conv')(pool1)\n",
    "    \n",
    "    pool2 = tf.layers.MaxPooling2D((3,3),(2,2),\n",
    "                                   name='MaxPool_2')(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'kernel_initializer')",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e20d3e19f30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mblock_3a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inception_3a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mblock_3b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_3a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inception_3b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MaxPool_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_3b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4f5693214135>\u001b[0m in \u001b[0;36minception_module\u001b[0;34m(prev_layer, one_conv_filters, reduced_three_filters, three_conv_filters, reduced_five_filters, five_conv_filters, after_poll_filters, module_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfive_conv_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhe_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'5x5_conv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhe_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3x3_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfive_conv_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhe_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'after_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/layers/pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool_size, strides, padding, data_format, name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     super(MaxPooling2D, self).__init__(\n\u001b[1;32m    263\u001b[0m         \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         padding=padding, data_format=data_format, name=name, **kwargs)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         padding=padding, data_format=data_format, **kwargs)\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool_function, pool_size, strides, padding, data_format, name, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                name=None, **kwargs):\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     super(Layer, self).__init__(trainable=trainable, name=name, dtype=dtype,\n\u001b[0;32m---> 84\u001b[0;31m                                 **kwargs)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'kernel_initializer')"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    block_3a = inception_module(pool2, 64, 96, 128, 16, 32, 32, 'inception_3a')\n",
    "    block_3b = inception_module(block_3a, 128, 128, 192, 32, 96, 64, 'inception_3b')\n",
    "    pool3 = tf.layers.MaxPooling2D((3,3), (2,2), padding='SAME', name='MaxPool_3')(block_3b)\n",
    "    \n",
    "    block_4a = inception_module(pool3, 192, 96, 208, 16, 48, 64, 'inception_4a')\n",
    "    block_4b = inception_module(block_4a, 160, 112, 224, 24, 64, 64, 'inception_4b')\n",
    "    block_4c = inception_module(block_4b, 128, 128, 256, 24, 64, 64, 'inception_4c')\n",
    "    block_4d = inception_module(block_4c, 112, 144, 288, 32, 64, 64, 'inception_4d')\n",
    "    blcok_4e = inception_module(block_4d, 256, 160, 320, 32, 128, 128, 'inception_4e')\n",
    "    pool4 = tf.layers.MaxPooling2D((3,3), (2,2), padding='SAME', name='MaxPool_4')(block_4e)\n",
    "    \n",
    "    block_5a = inception_module(pool4, 256, 160, 320, 32, 128, 128, 'inception_5a')\n",
    "    block_5b = inception_module(block_5a, 384, 192, 384, 48, 128, 128, 'inception_5b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.variable_scope('auxiliary_network_4a'):\n",
    "        avg_pool = tf.layers.AveragePooling2D((5,5), (3,3))(block_4a)\n",
    "        conv = tf.layers.Conv2D(128, (1,1), kernel_initializer=he_init,activation=tf.nn.relu,name = '1x1')(avg_pool)\n",
    "        \n",
    "        fc = tf.layers.Flatten()(conv)\n",
    "        fc = tf.layers.Dense(1024, kernel_initializer=he_init,activation=tf.nn.relu)(fc)\n",
    "        fc = tf.layers.Dropout(0.7)(fc)\n",
    "        aux_logit_4a = tf.layers.Dense(1000, kernel_initializer=xavier_init)(fc)\n",
    "        \n",
    "    with tf.variable_scope('auxiliary_network_4d'):\n",
    "        avg_pool = tf.layers.AveragePooling2D((5,5), (3,3))(block_4d)\n",
    "        conv = tf.layers.Conv2D(128, (1,1), kernel_initializer=he_init,activation=tf.nn.relu, name = '1x1')(avg_pool)\n",
    "        \n",
    "        fc = tf.layers.Flatten()(conv)\n",
    "        fc = tf.layers.Dense(1024, kernel_initializer=he_init, activation=tf.nn.relu)(fc)\n",
    "        fc = tf.layers.Dropout(0.7)(fc)\n",
    "        aux_logit_4d = tf.layers.Dense(1000, kernel_initializer=xavier_init)(fc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    labels = tf.placeholder(tf.int64, shape=(None, ), name='labels')\n",
    "    \n",
    "    with tf.variable_scope('losses'):\n",
    "        main_loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "        aux_4a_loss = tf.losses.sparse_softmax_cross_entropy(labels, aux_logit_4a) \n",
    "        aux_4d_loss = tf.losses.sparse_softmax_cross_entropy(labels, aux_logit_4d) \n",
    "        loss = main_loss + 0.3*aux_logit_4a + 0.3*aux_4d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    lr = tf.placeholder_with_default(1e-2, (), name='learning_rate')\n",
    "    train_op = tf.train.MomentumOptimizer(lr, 0.9).minimize(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.variable_scope('metrics'):\n",
    "        top_5, top_5_op = tf.metrics.mean(tf.cast(tf.nn.in_top_k(logits, labels, k=5), tf.float32) * 100)\n",
    "        \n",
    "        top_1, top_1_op = tf.metrics.mean(tf.cast(tf.nn.in_top_k(logits, labels, k=1), tf.float32) * 100)\n",
    "        \n",
    "        metric_loss, metric_loss_op = tf.metrics.mean(main_loss)\n",
    "        \n",
    "        metric_init_op = tf.group([var.initializer for var in graph.get_collection(tf.GraphKeys.METRIC_VARIABLES)], name='metric_update_op')\n",
    "        metric_update_op = tf.group([top_5_op, top_1_op, metric_loss_op], name='metric_update_op')\n",
    "        \n",
    "        top_5 = tf.identity(top_5, 'top5_acc')\n",
    "        top_1 = tf.identity(top_1, 'top1_acc')\n",
    "        metric_loss = tf.identity(metric_loss, 'metric_loss')\n",
    "        \n",
    "        tf.summary.scalar('top5_accuracy', top_5)\n",
    "        tf.summary.scalar('top1_accuracy', top_1)\n",
    "        tf.summary.scalar('loss', metric_loss)\n",
    "        merged = tf.summary.merge_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python36",
   "display_name": "Python 3.6",
   "language": "python"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6",
   "file_extension": ".py",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
