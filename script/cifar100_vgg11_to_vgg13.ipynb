{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "N8rYocJaRVHe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/Image-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j__l15BQJbJl",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153.0
    },
    "outputId": "5d6455b5-bf38-4b30-9d8a-663d487e88f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Image-Classification'...\n",
      "remote: Enumerating objects: 59, done.\u001b[K\n",
      "remote: Counting objects:   1% (1/59)   \u001b[K\rremote: Counting objects:   3% (2/59)   \u001b[K\rremote: Counting objects:   5% (3/59)   \u001b[K\rremote: Counting objects:   6% (4/59)   \u001b[K\rremote: Counting objects:   8% (5/59)   \u001b[K\rremote: Counting objects:  10% (6/59)   \u001b[K\rremote: Counting objects:  11% (7/59)   \u001b[K\rremote: Counting objects:  13% (8/59)   \u001b[K\rremote: Counting objects:  15% (9/59)   \u001b[K\rremote: Counting objects:  16% (10/59)   \u001b[K\rremote: Counting objects:  18% (11/59)   \u001b[K\rremote: Counting objects:  20% (12/59)   \u001b[K\rremote: Counting objects:  22% (13/59)   \u001b[K\rremote: Counting objects:  23% (14/59)   \u001b[K\rremote: Counting objects:  25% (15/59)   \u001b[K\rremote: Counting objects:  27% (16/59)   \u001b[K\rremote: Counting objects:  28% (17/59)   \u001b[K\rremote: Counting objects:  30% (18/59)   \u001b[K\rremote: Counting objects:  32% (19/59)   \u001b[K\rremote: Counting objects:  33% (20/59)   \u001b[K\rremote: Counting objects:  35% (21/59)   \u001b[K\rremote: Counting objects:  37% (22/59)   \u001b[K\rremote: Counting objects:  38% (23/59)   \u001b[K\rremote: Counting objects:  40% (24/59)   \u001b[K\rremote: Counting objects:  42% (25/59)   \u001b[K\rremote: Counting objects:  44% (26/59)   \u001b[K\rremote: Counting objects:  45% (27/59)   \u001b[K\rremote: Counting objects:  47% (28/59)   \u001b[K\rremote: Counting objects:  49% (29/59)   \u001b[K\rremote: Counting objects:  50% (30/59)   \u001b[K\rremote: Counting objects:  52% (31/59)   \u001b[K\rremote: Counting objects:  54% (32/59)   \u001b[K\rremote: Counting objects:  55% (33/59)   \u001b[K\rremote: Counting objects:  57% (34/59)   \u001b[K\rremote: Counting objects:  59% (35/59)   \u001b[K\rremote: Counting objects:  61% (36/59)   \u001b[K\rremote: Counting objects:  62% (37/59)   \u001b[K\rremote: Counting objects:  64% (38/59)   \u001b[K\rremote: Counting objects:  66% (39/59)   \u001b[K\rremote: Counting objects:  67% (40/59)   \u001b[K\rremote: Counting objects:  69% (41/59)   \u001b[K\rremote: Counting objects:  71% (42/59)   \u001b[K\rremote: Counting objects:  72% (43/59)   \u001b[K\rremote: Counting objects:  74% (44/59)   \u001b[K\rremote: Counting objects:  76% (45/59)   \u001b[K\rremote: Counting objects:  77% (46/59)   \u001b[K\rremote: Counting objects:  79% (47/59)   \u001b[K\rremote: Counting objects:  81% (48/59)   \u001b[K\rremote: Counting objects:  83% (49/59)   \u001b[K\rremote: Counting objects:  84% (50/59)   \u001b[K\rremote: Counting objects:  86% (51/59)   \u001b[K\rremote: Counting objects:  88% (52/59)   \u001b[K\rremote: Counting objects:  89% (53/59)   \u001b[K\rremote: Counting objects:  91% (54/59)   \u001b[K\rremote: Counting objects:  93% (55/59)   \u001b[K\rremote: Counting objects:  94% (56/59)   \u001b[K\rremote: Counting objects:  96% (57/59)   \u001b[K\rremote: Counting objects:  98% (58/59)   \u001b[K\rremote: Counting objects: 100% (59/59)   \u001b[K\rremote: Counting objects: 100% (59/59), done.\u001b[K\n",
      "remote: Compressing objects:   2% (1/37)   \u001b[K\rremote: Compressing objects:   5% (2/37)   \u001b[K\rremote: Compressing objects:   8% (3/37)   \u001b[K\rremote: Compressing objects:  10% (4/37)   \u001b[K\rremote: Compressing objects:  13% (5/37)   \u001b[K\rremote: Compressing objects:  16% (6/37)   \u001b[K\rremote: Compressing objects:  18% (7/37)   \u001b[K\rremote: Compressing objects:  21% (8/37)   \u001b[K\rremote: Compressing objects:  24% (9/37)   \u001b[K\rremote: Compressing objects:  27% (10/37)   \u001b[K\rremote: Compressing objects:  29% (11/37)   \u001b[K\rremote: Compressing objects:  32% (12/37)   \u001b[K\rremote: Compressing objects:  35% (13/37)   \u001b[K\rremote: Compressing objects:  37% (14/37)   \u001b[K\rremote: Compressing objects:  40% (15/37)   \u001b[K\rremote: Compressing objects:  43% (16/37)   \u001b[K\rremote: Compressing objects:  45% (17/37)   \u001b[K\rremote: Compressing objects:  48% (18/37)   \u001b[K\rremote: Compressing objects:  51% (19/37)   \u001b[K\rremote: Compressing objects:  54% (20/37)   \u001b[K\rremote: Compressing objects:  56% (21/37)   \u001b[K\rremote: Compressing objects:  59% (22/37)   \u001b[K\rremote: Compressing objects:  62% (23/37)   \u001b[K\rremote: Compressing objects:  64% (24/37)   \u001b[K\rremote: Compressing objects:  67% (25/37)   \u001b[K\rremote: Compressing objects:  70% (26/37)   \u001b[K\rremote: Compressing objects:  72% (27/37)   \u001b[K\rremote: Compressing objects:  75% (28/37)   \u001b[K\rremote: Compressing objects:  78% (29/37)   \u001b[K\rremote: Compressing objects:  81% (30/37)   \u001b[K\rremote: Compressing objects:  83% (31/37)   \u001b[K\rremote: Compressing objects:  86% (32/37)   \u001b[K\rremote: Compressing objects:  89% (33/37)   \u001b[K\rremote: Compressing objects:  91% (34/37)   \u001b[K\rremote: Compressing objects:  94% (35/37)   \u001b[K\rremote: Compressing objects:  97% (36/37)   \u001b[K\rremote: Compressing objects: 100% (37/37)   \u001b[K\rremote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "Receiving objects:   0% (1/351)   \rReceiving objects:   1% (4/351)   \rReceiving objects:   2% (8/351)   \rReceiving objects:   3% (11/351)   \rReceiving objects:   4% (15/351)   \rReceiving objects:   5% (18/351)   \rReceiving objects:   6% (22/351)   \rReceiving objects:   7% (25/351)   \rReceiving objects:   8% (29/351)   \rReceiving objects:   9% (32/351)   \rReceiving objects:  10% (36/351)   \rReceiving objects:  11% (39/351)   \rReceiving objects:  12% (43/351)   \rReceiving objects:  13% (46/351)   \rReceiving objects:  14% (50/351)   \rReceiving objects:  15% (53/351)   \rReceiving objects:  16% (57/351)   \rReceiving objects:  17% (60/351)   \rReceiving objects:  18% (64/351)   \rReceiving objects:  19% (67/351)   \rReceiving objects:  20% (71/351)   \rReceiving objects:  21% (74/351)   \rReceiving objects:  22% (78/351)   \rReceiving objects:  23% (81/351)   \rReceiving objects:  24% (85/351)   \rReceiving objects:  25% (88/351)   \rReceiving objects:  26% (92/351)   \rReceiving objects:  27% (95/351)   \rReceiving objects:  28% (99/351)   \rReceiving objects:  29% (102/351)   \rReceiving objects:  30% (106/351)   \rReceiving objects:  31% (109/351)   \rReceiving objects:  32% (113/351)   \rReceiving objects:  33% (116/351)   \rReceiving objects:  34% (120/351)   \rReceiving objects:  35% (123/351)   \rReceiving objects:  36% (127/351)   \rReceiving objects:  37% (130/351)   \rReceiving objects:  38% (134/351)   \rReceiving objects:  39% (137/351)   \rReceiving objects:  40% (141/351)   \rReceiving objects:  41% (144/351)   \rReceiving objects:  42% (148/351)   \rReceiving objects:  43% (151/351)   \rReceiving objects:  44% (155/351)   \rReceiving objects:  45% (158/351)   \rReceiving objects:  46% (162/351)   \rReceiving objects:  47% (165/351)   \rReceiving objects:  48% (169/351)   \rReceiving objects:  49% (172/351)   \rReceiving objects:  50% (176/351)   \rReceiving objects:  51% (180/351)   \rReceiving objects:  52% (183/351)   \rReceiving objects:  53% (187/351)   \rReceiving objects:  54% (190/351)   \rReceiving objects:  55% (194/351)   \rReceiving objects:  56% (197/351)   \rReceiving objects:  57% (201/351)   \rReceiving objects:  58% (204/351)   \rReceiving objects:  59% (208/351)   \rReceiving objects:  60% (211/351)   \rReceiving objects:  61% (215/351)   \rReceiving objects:  62% (218/351)   \rReceiving objects:  63% (222/351)   \rReceiving objects:  64% (225/351)   \rReceiving objects:  65% (229/351)   \rReceiving objects:  66% (232/351)   \rReceiving objects:  67% (236/351)   \rReceiving objects:  68% (239/351)   \rReceiving objects:  69% (243/351)   \rremote: Total 351 (delta 32), reused 46 (delta 22), pack-reused 292\u001b[K\n",
      "Receiving objects:  70% (246/351)   \rReceiving objects:  71% (250/351)   \rReceiving objects:  72% (253/351)   \rReceiving objects:  73% (257/351)   \rReceiving objects:  74% (260/351)   \rReceiving objects:  75% (264/351)   \rReceiving objects:  76% (267/351)   \rReceiving objects:  77% (271/351)   \rReceiving objects:  78% (274/351)   \rReceiving objects:  79% (278/351)   \rReceiving objects:  80% (281/351)   \rReceiving objects:  81% (285/351)   \rReceiving objects:  82% (288/351)   \rReceiving objects:  83% (292/351)   \rReceiving objects:  84% (295/351)   \rReceiving objects:  85% (299/351)   \rReceiving objects:  86% (302/351)   \rReceiving objects:  87% (306/351)   \rReceiving objects:  88% (309/351)   \rReceiving objects:  89% (313/351)   \rReceiving objects:  90% (316/351)   \rReceiving objects:  91% (320/351)   \rReceiving objects:  92% (323/351)   \rReceiving objects:  93% (327/351)   \rReceiving objects:  94% (330/351)   \rReceiving objects:  95% (334/351)   \rReceiving objects:  96% (337/351)   \rReceiving objects:  97% (341/351)   \rReceiving objects:  98% (344/351)   \rReceiving objects:  99% (348/351)   \rReceiving objects: 100% (351/351)   \rReceiving objects: 100% (351/351), 64.62 KiB | 4.31 MiB/s, done.\n",
      "Resolving deltas:   0% (0/200)   \rResolving deltas:   1% (2/200)   \rResolving deltas:   9% (18/200)   \rResolving deltas:  12% (25/200)   \rResolving deltas:  16% (32/200)   \rResolving deltas:  17% (34/200)   \rResolving deltas:  19% (38/200)   \rResolving deltas:  22% (45/200)   \rResolving deltas:  35% (70/200)   \rResolving deltas:  36% (72/200)   \rResolving deltas:  37% (75/200)   \rResolving deltas:  39% (79/200)   \rResolving deltas:  41% (83/200)   \rResolving deltas:  47% (94/200)   \rResolving deltas:  53% (106/200)   \rResolving deltas:  56% (113/200)   \rResolving deltas:  57% (115/200)   \rResolving deltas:  59% (119/200)   \rResolving deltas:  60% (120/200)   \rResolving deltas:  62% (125/200)   \rResolving deltas:  65% (131/200)   \rResolving deltas:  67% (135/200)   \rResolving deltas:  70% (140/200)   \rResolving deltas:  74% (149/200)   \rResolving deltas:  75% (151/200)   \rResolving deltas:  76% (152/200)   \rResolving deltas:  77% (154/200)   \rResolving deltas:  80% (161/200)   \rResolving deltas:  81% (163/200)   \rResolving deltas:  82% (165/200)   \rResolving deltas:  83% (166/200)   \rResolving deltas:  86% (172/200)   \rResolving deltas:  87% (174/200)   \rResolving deltas:  88% (176/200)   \rResolving deltas:  89% (179/200)   \rResolving deltas:  91% (182/200)   \rResolving deltas:  92% (184/200)   \rResolving deltas:  94% (189/200)   \rResolving deltas:  95% (191/200)   \rResolving deltas:  96% (193/200)   \rResolving deltas:  97% (194/200)   \rResolving deltas:  98% (197/200)   \rResolving deltas:  99% (199/200)   \rResolving deltas: 100% (200/200)   \rResolving deltas: 100% (200/200), done.\n",
      "/content/Image-Classification\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/anthony0727/Image-Classification.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hUvryE-E44vr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "769bb7c0-289a-419c-f124-d0a65242aa42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Image-Classification\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Image-Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Xb5XnacRm7P",
    "colab_type": "text"
   },
   "source": [
    "# Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ka_9iORQIfS1",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207.0
    },
    "outputId": "0a215ff8-9404-4810-e00c-33831433ac06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 08:54:25.826234 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/googlenet.py:9: The name tf.initializers.he_uniform is deprecated. Please use tf.compat.v1.initializers.he_uniform instead.\n",
      "\n",
      "W0722 08:54:25.828428 140326408988544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0722 08:54:25.833087 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:14: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0722 08:54:25.838398 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/util/jpynb_helper.py:3: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "from model.vgg import VGG\n",
    "from util import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzsQr7LVRuaq",
    "colab_type": "text"
   },
   "source": [
    "# Declare Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Fy-lLK8tIkGd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XGTCjTHuIg8x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "n_class = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW0eBF27R0M6",
    "colab_type": "text"
   },
   "source": [
    "# Build VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IHj7bz2hIiUT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479.0
    },
    "outputId": "7ff6f432-60cf-456f-bf41-be9150edb759"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 08:54:26.489790 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/ABCNet.py:19: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0722 08:54:26.494073 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:65: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 08:54:26.500527 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:75: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0722 08:54:26.501930 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:26: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "W0722 08:54:26.742947 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:41: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "W0722 08:54:27.024692 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:78: The name tf.layers.Flatten is deprecated. Please use tf.compat.v1.layers.Flatten instead.\n",
      "\n",
      "W0722 08:54:27.373753 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:32: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "W0722 08:54:27.690795 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:33: The name tf.layers.Dropout is deprecated. Please use tf.compat.v1.layers.Dropout instead.\n",
      "\n",
      "W0722 08:54:27.837330 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:91: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0722 08:54:27.871364 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:103: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "W0722 08:54:27.894674 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:105: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "W0722 08:54:27.955592 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:118: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0722 08:54:27.963018 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/model/vgg.py:121: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_vgg = VGG(11)\n",
    "pretrained_vgg.build(input_shape, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0H1sHZGR7EP",
    "colab_type": "text"
   },
   "source": [
    "# Pretrain VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gRuKFQr5IlcA",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190.0
    },
    "outputId": "c6b0376d-0ddf-4d02-ef87-cf6ced726458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "W0722 08:54:30.011411 140326408988544 deprecation_wrapper.py:119] From /content/Image-Classification/util/train_helper.py:33: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "100%|██████████| 390/390 [00:29<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 epoch train top-1 acc : 2.17% | top-5 acc : 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/390 [00:00<00:29, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 epoch test top-1 acc : 1.70% | top-5 acc : 8.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:28<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 epoch train top-1 acc : 2.06% | top-5 acc : 10.59%\n",
      "[  1 epoch test top-1 acc : 1.20% | top-5 acc : 10.20%\n"
     ]
    }
   ],
   "source": [
    "with pretrained_vgg.graph.as_default() as graph:\n",
    "    loss = graph.get_tensor_by_name('loss:0')\n",
    "    lr = tf.placeholder_with_default(1e-2, (), name='learning_rate')\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        tf.train.MomentumOptimizer(lr, 0.9).minimize(loss, global_step)\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "    sess = train(sess, log_dir, n_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Q5gidCAmjV7N",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with pretrained_vgg.graph.as_default() as graph:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './vgg/vgg11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2jeMX9NSHUJ",
    "colab_type": "text"
   },
   "source": [
    "# Reserve some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xlrSdK9_Krw5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "a999f696-ccf3-4703-9d09-091376fddc72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pretrained_vgg.graph\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT4dBwELSQYW",
    "colab_type": "text"
   },
   "source": [
    "# Build VGG13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ug5zfyUIIodi",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "reconstructed_vgg = VGG(13)\n",
    "reconstructed_vgg.build(input_shape, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXah-GlsSUYB",
    "colab_type": "text"
   },
   "source": [
    "# Collect weights to transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "U71z9bSXIqaE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with reconstructed_vgg.graph.as_default():\n",
    "    transfer_weights = \\\n",
    "        tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, '(VGGBLOCK-1/conv1)') + \\\n",
    "        tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, '(VGGBLOCK-2/conv1)') + \\\n",
    "        tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, '(VGGBLOCK-3/conv1|conv2)') + \\\n",
    "        tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'FC/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmNWeANCSZry",
    "colab_type": "text"
   },
   "source": [
    "# Restore pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dItAGWYbId9C",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88.0
    },
    "outputId": "79b11621-9ead-4800-f200-2333f38338a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 08:55:53.791559 140326408988544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "with reconstructed_vgg.graph.as_default() as graph:\n",
    "    sess = tf.Session(graph=graph)\n",
    "    \n",
    "    saver = tf.train.Saver(var_list=transfer_weights)\n",
    "    saver.restore(sess, './vgg/vgg11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "112Q74V20Y8P",
    "colab_type": "text"
   },
   "source": [
    "# Declare necessaries and do initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XlejLYw82msu",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess, vs):\n",
    "    with sess.graph.as_default():\n",
    "        is_not_initialized = sess.run([tf.is_variable_initialized(v) for v in vs])\n",
    "        uninitialized_vs = [v for (v, f) in zip(vs, is_not_initialized) if not f]\n",
    "        \n",
    "        if len(uninitialized_vs):\n",
    "            sess.run(tf.variables_initializer(uninitialized_vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "KceM8cNh0Xq4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with reconstructed_vgg.graph.as_default() as graph:\n",
    "    loss = graph.get_tensor_by_name('loss:0')\n",
    "    lr = tf.placeholder_with_default(1e-2, (), name='learning_rate')\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        tf.train.AdamOptimizer(lr).minimize(loss, global_step)\n",
    "\n",
    "    with tf.variable_scope('initialization'):\n",
    "        initialize_uninitialized(sess, tf.global_variables())\n",
    "        initialize_uninitialized(sess, tf.local_variables()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuIdVbQ_wsD7",
    "colab_type": "text"
   },
   "source": [
    "# Check accuracy consistency\n",
    "\n",
    "feed sample data to both vgg11 and vgg13 and check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-a4PC0835kPM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code",
    "outputId": "d8b61069-3fcf-481a-bb3f-4ceb1a8c8f8d",
    "id": "059d_J0400zR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    }
   },
   "source": [
    "with reconstructed_vgg.graph.as_default() as graph:\n",
    "    print(sess.run(graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)))\n",
    "    print(sess.run(graph.get_collection(tf.GraphKeys.METRIC_VARIABLES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2o2N_NySfMr",
    "colab_type": "text"
   },
   "source": [
    "# Train VGG13\n",
    "\n",
    "## initializer\n",
    "    \n",
    "\n",
    "## optimizer\n",
    "    AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HfEssVf3IuG9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139.0
    },
    "outputId": "8f59184d-2c1a-4730-8983-e0d18db7ce0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:37<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 epoch train top-1 acc : 1.00% | top-5 acc : 5.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/390 [00:00<00:39,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 epoch test top-1 acc : 1.50% | top-5 acc : 6.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:37<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 epoch train top-1 acc : 1.00% | top-5 acc : 5.00%\n",
      "[  1 epoch test top-1 acc : 1.10% | top-5 acc : 5.80%\n"
     ]
    }
   ],
   "source": [
    "with reconstructed_vgg.graph.as_default() as graph:\n",
    "    \n",
    "    sess = tf.Session(graph=graph)\n",
    "    sess = train(sess, log_dir, n_epoch=2)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './vgg/vgg11')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cifar100_vgg11_to_vgg13.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
